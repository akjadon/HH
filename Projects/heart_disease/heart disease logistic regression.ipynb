{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nAim : Predict person has heart disease or not<br/>\n      Study and Learn Logistic Regression\n* EDA\n* Logistic Regression\n* Logistic Regression with Sklearn"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"* Data has target column\n* This is input (dependent variable)\n* Target has two unique value 1 and 0\n* 1 -> person has heart disease\n* 0 -> person has no heart disease"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"heart = pd.read_csv(\"../input/heart.csv\")\nheart.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is good because there is no missing value."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,10))\nsns.heatmap(heart.corr(),annot = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = heart.drop(\"target\",axis = 1)\ny = heart.target.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 42)\nprint(\"x_train : \",x_train.shape)\nprint(\"x_test : \",x_test.shape)\nprint(\"y_train : \",y_train.shape)\nprint(\"y_test : \",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okey,let's write logistic regression with own code."},{"metadata":{"trusted":true},"cell_type":"code","source":"class LogReg():\n    def forward_backward_propagation(self,w,b,x_train,y_train):\n        x_train = x_train.T #(13,242)\n        y_train = y_train.T #(242,)\n        w = w.T     # if we want to multiply two matrix,first matrix column number and second matrix row number must be equal.\n        z = np.dot(w,x_train)+b # This is our model\n        y_head = 1/(1+np.exp(-z)) # Sigmuid function\n        loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head) \n        cost = np.sum(loss)/x_train.shape[1] # cost function\n        \n        dw = np.dot(x_train,(y_head-y_train).T)/x_train.shape[1] #derivative weight\n        db = np.sum(y_head-y_train)/x_train.shape[1] #derivative bias\n        \n        gradients = {\"dw\":dw,\"db\":db}\n        \n        return cost,gradients\n    def fit(self,w,b,x_train,y_train,learn_rate,num_it):\n        #To reach most fit model we should update our model\n        self.cost_list = []\n        for i in range(num_it):\n            cost,gradients = self.forward_backward_propagation(w,b,x_train,y_train)\n            self.cost_list.append(cost)\n            \n            w = w - learn_rate*gradients[\"dw\"]# update weight\n            b = b - learn_rate*gradients[\"db\"]#update bias\n        #Last parameters\n        self.w = w\n        self.b = b\n        self.cost = self.cost_list[-1]\n    def predict(self,x_test):\n        x_test = x_test.T\n        z = np.dot(self.w,x_test)+self.b\n        y_head = 1/(1+np.exp(-z))\n        for i in range(len(y_head)):\n            if y_head[i] <= 0.5:\n                y_head[i] = 0\n            else:\n                y_head[i] = 1\n        return y_head\n    def score(self,x_test,y_test):\n        y_head = self.predict(x_test)\n        return 1-np.mean(np.abs(y_head-y_test))\n\n    \nw = np.full((x_train.shape[1]),0.01)#initial weight values\nb = 0.0 #initial bias value\n\nfrom sklearn.preprocessing import minmax_scale\nx_train = minmax_scale(x_train)#Normalize data\nx_test = minmax_scale(x_test)# (x-min(x))/(max(x)-min(x))\n\nlog_reg = LogReg()\nlog_reg.fit(w,b,x_train,y_train,2,300)\npredict = log_reg.score(x_test,y_test)\npredict2 = log_reg.score(x_train,y_train)\nprint(\"Test Accurary : {}\".format(predict))\nprint(\"Train Accurary : {}\".format(predict2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,7))\nplt.plot(np.arange(len(log_reg.cost_list)),np.array(log_reg.cost_list))#Change of cost function\nplt.title(\"Change of Cost Function\")\nplt.ylabel(\"Value of Cost Function\")\nplt.xlabel(\"Number of Iteration\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression with Sklearn"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\npredict = lr.score(x_test,y_test)\npredict2 = lr.score(x_train,y_train)\nprint(\"Test Accurary : {}\".format(predict))\nprint(\"Test Accurary : {}\".format(predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You see this is very easy with sklearn library"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}